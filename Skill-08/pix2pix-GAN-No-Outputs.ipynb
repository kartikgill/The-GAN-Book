{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Useful Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-07T13:02:44.769457Z",
     "start_time": "2020-12-07T13:02:43.919373Z"
    },
    "id": "14h4ejQKFVe9"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm_notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-07T13:02:47.196492Z",
     "start_time": "2020-12-07T13:02:44.771109Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UnlKaodtFVe9",
    "outputId": "0c6f194b-3af4-4f8b-f07a-ac152a13942b"
   },
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "print (tensorflow.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download and extract Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U1MwQJzBv4fg",
    "outputId": "96ecef5b-d780-47cc-cdff-95086298b573"
   },
   "outputs": [],
   "source": [
    "!wget http://efrosgans.eecs.berkeley.edu/pix2pix/datasets/maps.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V-S3bx0Jtnsf"
   },
   "outputs": [],
   "source": [
    "!tar -zxf maps.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sBkqfuNBv_WU",
    "outputId": "75a50bab-e8d1-4ea7-a45c-c0bf0f931aef"
   },
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sqJAMZclu3Ug"
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "train_files = glob.glob('maps/train/*.jpg')\n",
    "test_files = glob.glob('maps/val/*.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_AWsrK62xgZm",
    "outputId": "8d9deb90-1c09-4fba-83a7-fe1c60cf8c2f"
   },
   "outputs": [],
   "source": [
    "len(train_files), len(test_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RNRBpV1YxpLo",
    "outputId": "246b188c-0772-4358-814b-a247913b3873"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "for file in train_files[:10]:\n",
    "    map = cv2.imread(file)\n",
    "    print (map.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Display few Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-07T13:02:48.712168Z",
     "start_time": "2020-12-07T13:02:47.646563Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 539
    },
    "id": "s0l5lTN_FVe-",
    "outputId": "ac454956-10f1-482e-e162-d45447f34036"
   },
   "outputs": [],
   "source": [
    "for k in range(3):\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    for j in range(3):\n",
    "        file = np.random.choice(train_files)\n",
    "        map = cv2.imread(file)\n",
    "        map = cv2.cvtColor(map, cv2.COLOR_BGR2RGB)\n",
    "        plt.subplot(330 + 1 + j)\n",
    "        plt.imshow(map)\n",
    "        plt.axis('off')\n",
    "        #plt.title(trainY[i])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input vs Output images separately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 560
    },
    "id": "NNKpyZILyntz",
    "outputId": "c468b875-1d48-4574-e8b0-767ddaaf83f4"
   },
   "outputs": [],
   "source": [
    "maps = []\n",
    "for j in range(3):\n",
    "    file = np.random.choice(train_files)\n",
    "    map = cv2.imread(file)\n",
    "    map = cv2.cvtColor(map, cv2.COLOR_BGR2RGB)\n",
    "    maps.append(map)\n",
    "\n",
    "print ('Input Images')\n",
    "plt.figure(figsize=(15, 15))\n",
    "for j, map in enumerate(maps):\n",
    "    map1 = map[:, :map.shape[1]//2]\n",
    "    plt.subplot(330 + 1 + j)\n",
    "    plt.imshow(map1)\n",
    "    plt.axis('off')\n",
    "    #plt.title(trainY[i])\n",
    "plt.show()\n",
    "\n",
    "print ('Output Images')\n",
    "plt.figure(figsize=(15, 15))\n",
    "for j, map in enumerate(maps):\n",
    "    map2 = map[:, map.shape[1]//2:]\n",
    "    plt.subplot(330 + 1 + j)\n",
    "    plt.imshow(map2)\n",
    "    plt.axis('off')\n",
    "    #plt.title(trainY[i])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kxFTsuaGFVe-"
   },
   "source": [
    "# Define Generator Model (U-Net Like)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4KVKCXC8RE6w"
   },
   "outputs": [],
   "source": [
    "import tensorflow_addons as tfa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-07T13:02:50.125060Z",
     "start_time": "2020-12-07T13:02:50.114135Z"
    },
    "id": "-jTan_A1tX1k"
   },
   "outputs": [],
   "source": [
    "def encoder_layer(input_layer, filters, bn=True):\n",
    "    x = tensorflow.keras.layers.Conv2D(filters, kernel_size=(4,4), strides=(2,2), padding='same')(input_layer)\n",
    "    x = tensorflow.keras.layers.LeakyReLU(alpha=0.2)(x)\n",
    "    if bn:\n",
    "        x = tfa.layers.InstanceNormalization()(x)\n",
    "    return x\n",
    "\n",
    "def decoder_layer(input_layer, skip_input, filters):\n",
    "    x = tensorflow.keras.layers.Conv2DTranspose(filters, kernel_size=(4,4), strides=(2,2), padding='same')(input_layer)\n",
    "    x = tensorflow.keras.layers.Activation('relu')(x)\n",
    "    x = tfa.layers.InstanceNormalization()(x)\n",
    "    x = tensorflow.keras.layers.Concatenate()([x, skip_input])\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-07T13:03:02.197040Z",
     "start_time": "2020-12-07T13:03:01.557548Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6B64_Tl5tX1k",
    "outputId": "1f4a49b4-d71d-4393-920b-6bf301895e02"
   },
   "outputs": [],
   "source": [
    "source_image_input = tensorflow.keras.layers.Input(shape=(256, 256, 3))\n",
    "\n",
    "e1 = encoder_layer(source_image_input, 64, bn=False)#64\n",
    "e2 = encoder_layer(e1, 128)#128\n",
    "e3 = encoder_layer(e2, 256)#256\n",
    "e4 = encoder_layer(e3, 512)#512\n",
    "e5 = encoder_layer(e4, 512)#512\n",
    "e6 = encoder_layer(e5, 512)#512\n",
    "e7 = encoder_layer(e6, 512)#512\n",
    "\n",
    "bottle_neck = tensorflow.keras.layers.Conv2D(512, (4,4), strides=(2,2), padding='same')(e7)\n",
    "b = tensorflow.keras.layers.Activation('relu')(bottle_neck)\n",
    "\n",
    "d1 = decoder_layer(b, e7, 512)#512\n",
    "d2 = decoder_layer(d1, e6, 512)#512\n",
    "d3 = decoder_layer(d2, e5, 512)#512\n",
    "d4 = decoder_layer(d3, e4, 512)#512\n",
    "d5 = decoder_layer(d4, e3, 256)#256\n",
    "d6 = decoder_layer(d5, e2, 128)#128\n",
    "d7 = decoder_layer(d6, e1, 64)#64\n",
    "\n",
    "decoded = tensorflow.keras.layers.Conv2DTranspose(3, kernel_size=(4,4), strides=(2,2), padding='same')(d7)\n",
    "translated_image = tensorflow.keras.layers.Activation('tanh')(decoded)\n",
    "\n",
    "generator_network = tensorflow.keras.models.Model(inputs=source_image_input, outputs=translated_image)\n",
    "print (generator_network.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CKXvIJKaFVe-"
   },
   "source": [
    "# Define Discriminator Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-07T10:25:12.489401Z",
     "start_time": "2020-12-07T10:25:12.484739Z"
    },
    "id": "nx2mZJvjtX1l"
   },
   "outputs": [],
   "source": [
    "def my_conv_layer(input_layer, filters, bn=True):\n",
    "    x = tensorflow.keras.layers.Conv2D(filters, kernel_size=(4,4), strides=(2,2), padding='same')(input_layer)\n",
    "    x = tensorflow.keras.layers.LeakyReLU(alpha=0.2)(x)\n",
    "    if bn:\n",
    "        x = tfa.layers.InstanceNormalization()(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-07T10:25:12.803702Z",
     "start_time": "2020-12-07T10:25:12.680014Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NIY6l2WNtX1l",
    "outputId": "7617e0c0-f515-4083-f12a-e2f30ef73602"
   },
   "outputs": [],
   "source": [
    "source_image_input = tensorflow.keras.layers.Input(shape=(256, 256, 3))\n",
    "target_image_input = tensorflow.keras.layers.Input(shape=(256, 256, 3))\n",
    "\n",
    "combined = tensorflow.keras.layers.Concatenate(axis=-1)([source_image_input, target_image_input])\n",
    "\n",
    "x = my_conv_layer(combined, 64, bn=False)#64\n",
    "x = my_conv_layer(x, 128)#128\n",
    "x = my_conv_layer(x, 256)#256\n",
    "x = my_conv_layer(x, 512)#512\n",
    "\n",
    "patch_features = tensorflow.keras.layers.Conv2D(1, kernel_size=(4,4), strides=(1,1), padding='same')(x)\n",
    "\n",
    "discriminator_network = tensorflow.keras.models.Model(inputs=[source_image_input, target_image_input], outputs=patch_features)\n",
    "print (discriminator_network.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-07T10:25:13.348271Z",
     "start_time": "2020-12-07T10:25:13.337184Z"
    },
    "id": "tMc1CyNNFVe-"
   },
   "outputs": [],
   "source": [
    "adam_optimizer = tensorflow.keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5)\n",
    "discriminator_network.compile(loss='mse', optimizer=adam_optimizer, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "99IlAN3AFVe-"
   },
   "source": [
    "# Define Pix2Pix GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-07T10:25:22.270580Z",
     "start_time": "2020-12-07T10:25:22.033613Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mjnxFr21FVe-",
    "outputId": "faa6d5dc-43e6-4cf7-9607-8b2cb10bd0f1"
   },
   "outputs": [],
   "source": [
    "discriminator_network.trainable=False\n",
    "\n",
    "g_output = generator_network(source_image_input)\n",
    "d_output = discriminator_network([source_image_input, g_output])\n",
    "\n",
    "pix2pix = tensorflow.keras.models.Model(inputs=source_image_input, outputs=[d_output, g_output])\n",
    "pix2pix.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MFyjhkyCFVe_"
   },
   "source": [
    "# Compiling Pix2Pix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-07T10:26:00.111801Z",
     "start_time": "2020-12-07T10:26:00.098374Z"
    },
    "id": "rPG_olwXFVe_"
   },
   "outputs": [],
   "source": [
    "pix2pix.compile(loss=['mse', 'mae'], optimizer=adam_optimizer, loss_weights=[1, 100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5RpVWMO8FVe_"
   },
   "source": [
    "# Define Data Generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-07T10:47:14.082629Z",
     "start_time": "2020-12-07T10:47:14.062561Z"
    },
    "id": "pTSivi-dFVe_"
   },
   "outputs": [],
   "source": [
    "def get_predictions(input_sample, generator_network):\n",
    "    input_sample = np.expand_dims(input_sample, axis=0)\n",
    "    output_sample = generator_network.predict_on_batch(input_sample)\n",
    "    return output_sample\n",
    "\n",
    "def get_generated_samples(generator_network, maps_input):\n",
    "    generated_samples = generator_network.predict_on_batch(maps_input)\n",
    "    return generated_samples\n",
    "\n",
    "def get_map_samples(batch_size):\n",
    "    random_files = np.random.choice(train_files, size=batch_size)\n",
    "    maps_input = []\n",
    "    maps_output = []\n",
    "    for file in random_files:\n",
    "        map = cv2.imread(file)\n",
    "        map = cv2.cvtColor(map, cv2.COLOR_BGR2RGB)\n",
    "        map1 = map[:, :map.shape[1]//2]\n",
    "        map2 = map[:, map.shape[1]//2:]\n",
    "        map1 = cv2.resize(map1, (256, 256))\n",
    "        map2 = cv2.resize(map2, (256, 256))\n",
    "        maps_input.append((map1-127.5)/127.5)\n",
    "        maps_output.append((map2-127.5)/127.5)\n",
    "    maps_input = np.array(maps_input)\n",
    "    maps_output = np.array(maps_output)\n",
    "    return maps_input, maps_output\n",
    "\n",
    "def show_generator_results(generator_network):\n",
    "    maps = []\n",
    "    for j in range(3):\n",
    "        file = np.random.choice(test_files)\n",
    "        map = cv2.imread(file)\n",
    "        map = cv2.cvtColor(map, cv2.COLOR_BGR2RGB)\n",
    "        maps.append(map)\n",
    "\n",
    "    print ('Input Images')\n",
    "    plt.figure(figsize=(13, 13))\n",
    "    for j, map in enumerate(maps):\n",
    "        map1 = map[:, :map.shape[1]//2]\n",
    "        map1 = cv2.resize(map1, (256, 256))\n",
    "        plt.subplot(330 + 1 + j)\n",
    "        plt.imshow(map1)\n",
    "        plt.axis('off')\n",
    "        #plt.title(trainY[i])\n",
    "    plt.show()\n",
    "\n",
    "    print ('Predicted Output Images')\n",
    "    plt.figure(figsize=(13, 13))\n",
    "    for j, map in enumerate(maps):\n",
    "        map1 = map[:, :map.shape[1]//2]\n",
    "        map1 = cv2.resize(map1, (256, 256))\n",
    "        map1 = (map1-127.5)/127.5\n",
    "        output = get_predictions(map1, generator_network)[0]\n",
    "        output = (output+1.0)/2.0\n",
    "        plt.subplot(330 + 1 + j)\n",
    "        plt.imshow(output)\n",
    "        plt.axis('off')\n",
    "        #plt.title(trainY[i])\n",
    "    plt.show()\n",
    "\n",
    "    print ('Real Output Images')\n",
    "    plt.figure(figsize=(13, 13))\n",
    "    for j, map in enumerate(maps):\n",
    "        map2 = map[:, map.shape[1]//2:]\n",
    "        map2 = cv2.resize(map2, (256, 256))\n",
    "        plt.subplot(330 + 1 + j)\n",
    "        plt.imshow(map2)\n",
    "        plt.axis('off')\n",
    "        #plt.title(trainY[i])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fEOpY_BZFVe_"
   },
   "source": [
    "# Training GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qm7HzaxI4HMt",
    "outputId": "06bcabf1-d5f9-466c-a040-6ec6c9a3332b"
   },
   "outputs": [],
   "source": [
    "len(train_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-07T10:52:58.115686Z",
     "start_time": "2020-12-07T10:52:58.063285Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "E_nihCaQFVe_",
    "outputId": "35b95c64-1adf-4fbb-dcae-a7104224e5dd"
   },
   "outputs": [],
   "source": [
    "epochs = 500\n",
    "batch_size = 1\n",
    "steps = 1096\n",
    "\n",
    "for i in range(0, epochs):\n",
    "    if (i%5 == 0):\n",
    "        show_generator_results(generator_network)\n",
    "    for j in range(steps):\n",
    "        maps_input, maps_output = get_map_samples(batch_size=batch_size)\n",
    "        generated_maps_output = get_generated_samples(generator_network, maps_input)\n",
    "\n",
    "        fake_patch = np.zeros((batch_size, 16, 16, 1))\n",
    "        real_patch = np.ones((batch_size, 16, 16, 1))\n",
    "        \n",
    "        # Updating Discriminator weights\n",
    "        discriminator_network.trainable=True\n",
    "        loss_d1 = discriminator_network.train_on_batch([maps_input, maps_output], real_patch)\n",
    "        loss_d2 = discriminator_network.train_on_batch([maps_input, generated_maps_output], fake_patch)\n",
    "        \n",
    "        loss_d = (np.add(loss_d1, loss_d2))/2.0\n",
    "        \n",
    "        \n",
    "        maps_input, maps_output = get_map_samples(batch_size=batch_size)\n",
    "        \n",
    "        # Make the Discriminator belive that these are real samples and calculate loss to train the generator\n",
    "        real_patch = np.ones((batch_size, 16, 16, 1))\n",
    "        \n",
    "        # Updating Generator weights\n",
    "        discriminator_network.trainable=False\n",
    "        loss_g, _, _ = pix2pix.train_on_batch(maps_input, [real_patch, maps_output])\n",
    "        \n",
    "        if j%100 == 0:\n",
    "            print (\"Epoch:%.0f, Step:%.0f, D-Loss:%.3f, D-Acc:%.3f, G-Loss:%.3f\"%(i,j,loss_d[0],loss_d[1]*100,loss_g))   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "OtkUT-YzKOFU",
    "outputId": "9a3e0f44-6baf-450c-8cbf-edc8c6a6c9d8",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    show_generator_results(generator_network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fOsgPm0eM4-0"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "pix2pix-GAN-maps.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
