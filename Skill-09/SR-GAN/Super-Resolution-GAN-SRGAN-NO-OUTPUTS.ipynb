{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kartikgill/The-GAN-Book/blob/main/Skill-09/SR-GAN/Super-Resolution-GAN-SRGAN-NO-OUTPUTS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ibd0SY1RzwKN"
      },
      "source": [
        "# Import Useful Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-12-24T12:15:30.136005Z",
          "start_time": "2020-12-24T12:15:29.141138Z"
        },
        "id": "14h4ejQKFVe9"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm_notebook\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-12-24T12:15:33.557046Z",
          "start_time": "2020-12-24T12:15:30.137708Z"
        },
        "id": "UnlKaodtFVe9",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "import tensorflow\n",
        "print (tensorflow.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R6gFXVvCzwKS"
      },
      "source": [
        "# Load and Unzip Data ->"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mfSsVGCJOx4c"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q9eZyQ-4NK82"
      },
      "outputs": [],
      "source": [
        "!unzip /content/gdrive/MyDrive/GAN_datasets/face_scrub.zip -d /"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AzXCheJANSDZ"
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "train = glob.glob('/*_faces/*/*.jpeg')[:35000]\n",
        "test = glob.glob('/*_faces/*/*.jpeg')[35000:]\n",
        "len(train), len(test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J3YET-WhC8xM"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "for file in train[:10]:\n",
        "    img = cv2.imread(file)\n",
        "    print (img.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HBQdsXi6zwKW"
      },
      "source": [
        "# Display Data Samples (64x64 --> 256x256)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cq1jzVQeNSF_"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "\n",
        "files = np.random.choice(train, size=4)\n",
        "\n",
        "print (\"Low quality Samples\")\n",
        "for k in range(1):\n",
        "    plt.figure(figsize=(15, 15))\n",
        "    for j, file in enumerate(files):\n",
        "        img = cv2.imread(file)\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        img = cv2.resize(img, (64, 64))\n",
        "        plt.subplot(440 + 1 + j)\n",
        "        plt.imshow(img)\n",
        "        plt.axis('off')\n",
        "        #plt.title(trainY[i])\n",
        "    plt.show()\n",
        "\n",
        "print (\"-\"*100)\n",
        "print (\"Real High quality version\")\n",
        "for k in range(1):\n",
        "    plt.figure(figsize=(15, 15))\n",
        "    for j, file in enumerate(files):\n",
        "        img = cv2.imread(file)\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        img = cv2.resize(img, (256, 256))\n",
        "        plt.subplot(440 + 1 + j)\n",
        "        plt.imshow(img)\n",
        "        plt.axis('off')\n",
        "        #plt.title(trainY[i])\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kxFTsuaGFVe-"
      },
      "source": [
        "# Define Generator Model (Resnet Like)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nk5D5FpaPdOq"
      },
      "outputs": [],
      "source": [
        "import tensorflow_addons as tfa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-12-24T13:13:43.451968Z",
          "start_time": "2020-12-24T13:13:43.441170Z"
        },
        "id": "chg3B1rdPq75"
      },
      "outputs": [],
      "source": [
        "def custom_resnet_block(input_layer, filters, upsample=False, resnet=True):\n",
        "    x = input_layer\n",
        "    if resnet==True:\n",
        "        x = tensorflow.keras.layers.Conv2D(filters, kernel_size=3, strides=1, padding='same')(x)\n",
        "        x = tensorflow.keras.layers.Activation('relu')(x)\n",
        "        x = tensorflow.keras.layers.BatchNormalization(momentum=0.8)(x)\n",
        "\n",
        "        x = tensorflow.keras.layers.Conv2D(filters, kernel_size=3, strides=1, padding='same')(x)\n",
        "        x = tfa.layers.InstanceNormalization()(x)\n",
        "\n",
        "        # Skip Connection\n",
        "        x = tensorflow.keras.layers.Add()([x, input_layer])\n",
        "    \n",
        "    if upsample==True:\n",
        "        x = tensorflow.keras.layers.UpSampling2D(size=2)(x)\n",
        "        x = tensorflow.keras.layers.Conv2D(filters, kernel_size=3, strides=1, padding='same')(x)\n",
        "        x = tensorflow.keras.layers.Activation('relu')(x)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-12-24T13:17:16.543450Z",
          "start_time": "2020-12-24T13:17:15.875177Z"
        },
        "id": "45iT4lb2Pq75"
      },
      "outputs": [],
      "source": [
        "low_quality_image = tensorflow.keras.layers.Input(shape=(64, 64, 3))\n",
        "\n",
        "first = tensorflow.keras.layers.Conv2D(64, kernel_size=9, strides=1, padding='same')(low_quality_image)\n",
        "first = tensorflow.keras.layers.Activation('relu')(first)\n",
        "\n",
        "x = custom_resnet_block(first, 64, False)\n",
        "x = custom_resnet_block(x, 64, False)\n",
        "x = custom_resnet_block(x, 64, False)\n",
        "x = custom_resnet_block(x, 64, False)\n",
        "\n",
        "x = custom_resnet_block(x, 64, False)\n",
        "x = custom_resnet_block(x, 64, False)\n",
        "x = custom_resnet_block(x, 64, False)\n",
        "x = custom_resnet_block(x, 64, False)\n",
        "\n",
        "x = custom_resnet_block(x, 64, False)\n",
        "x = custom_resnet_block(x, 64, False)\n",
        "x = custom_resnet_block(x, 64, False)\n",
        "x = custom_resnet_block(x, 64, False)\n",
        "\n",
        "x = custom_resnet_block(x, 64, False)\n",
        "x = custom_resnet_block(x, 64, False)\n",
        "x = custom_resnet_block(x, 64, False)\n",
        "x = custom_resnet_block(x, 64, False)\n",
        "\n",
        "y = tensorflow.keras.layers.Conv2D(64, kernel_size=3, strides=1, padding='same')(x)\n",
        "y = tensorflow.keras.layers.BatchNormalization(momentum=0.8)(y)\n",
        "y = tensorflow.keras.layers.Add()([y, first])\n",
        "\n",
        "z = custom_resnet_block(y, 256, True, False)\n",
        "z = custom_resnet_block(z, 256, True, False)\n",
        "\n",
        "z = tensorflow.keras.layers.Conv2D(3, kernel_size=9, strides=1, padding='same')(z)\n",
        "high_quality_image = tensorflow.keras.layers.Activation('tanh')(z)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-12-24T13:18:38.736242Z",
          "start_time": "2020-12-24T13:18:38.670823Z"
        },
        "id": "JSu29uBlPq75"
      },
      "outputs": [],
      "source": [
        "generator_network = tensorflow.keras.models.Model(inputs=low_quality_image, outputs=high_quality_image)\n",
        "print (generator_network.summary())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gIqorLAuPq76"
      },
      "source": [
        "# Define Discriminator Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-12-24T13:23:42.453037Z",
          "start_time": "2020-12-24T13:23:42.448750Z"
        },
        "id": "0nSu8-6NPq76"
      },
      "outputs": [],
      "source": [
        "def custom_d_block(input_layer, filters, strides, bn=True):\n",
        "    x = tensorflow.keras.layers.Conv2D(filters, kernel_size=3, strides=strides, padding='same')(input_layer)\n",
        "    x = tensorflow.keras.layers.LeakyReLU(alpha=0.2)(x)\n",
        "    if bn==True:\n",
        "        x = tfa.layers.InstanceNormalization()(x)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-12-24T13:36:32.692796Z",
          "start_time": "2020-12-24T13:36:32.483689Z"
        },
        "id": "VEq4-rqJPq76"
      },
      "outputs": [],
      "source": [
        "high_quality_input = tensorflow.keras.layers.Input(shape=(256, 256, 3))\n",
        "\n",
        "x = custom_d_block(high_quality_input, 64, 1, False)\n",
        "x = custom_d_block(x, 64, 2, True)\n",
        "x = custom_d_block(x, 128, 1, True)\n",
        "x = custom_d_block(x, 128, 2, True)\n",
        "x = custom_d_block(x, 256, 1, True)\n",
        "x = custom_d_block(x, 256, 2, True)\n",
        "x = custom_d_block(x, 512, 1, True)\n",
        "x = custom_d_block(x, 512, 2, True)\n",
        "\n",
        "x = tensorflow.keras.layers.Dense(1024)(x)\n",
        "x = tensorflow.keras.layers.LeakyReLU(alpha=0.2)(x)\n",
        "\n",
        "real_vs_fake_patch = tensorflow.keras.layers.Dense(1, activation='sigmoid')(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-12-24T13:36:32.721869Z",
          "start_time": "2020-12-24T13:36:32.703950Z"
        },
        "id": "9vR4Y-HnPq77"
      },
      "outputs": [],
      "source": [
        "discriminator_network = tensorflow.keras.models.Model(inputs=high_quality_input, outputs=real_vs_fake_patch)\n",
        "print (discriminator_network.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-12-24T14:02:42.898597Z",
          "start_time": "2020-12-24T14:02:42.883342Z"
        },
        "id": "tMc1CyNNFVe-"
      },
      "outputs": [],
      "source": [
        "adam_optimizer = tensorflow.keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5)\n",
        "\n",
        "discriminator_network.compile(loss='mse', optimizer=adam_optimizer, metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vjk8BzFlPq77"
      },
      "source": [
        "# Loading Pre Trained VGG feaures"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-12-24T14:23:07.467306Z",
          "start_time": "2020-12-24T14:22:57.559008Z"
        },
        "id": "3xDtTpkzPq77"
      },
      "outputs": [],
      "source": [
        "image_input = tensorflow.keras.layers.Input(shape=(256, 256, 3))\n",
        "\n",
        "pre_trained_vgg = tensorflow.keras.applications.vgg19.VGG19(weights='imagenet', input_shape=(256, 256, 3), include_top=False)\n",
        "pre_trained_vgg_model = tensorflow.keras.models.Model(inputs=pre_trained_vgg.input, outputs=pre_trained_vgg.get_layer('block3_conv4').output)\n",
        "\n",
        "pre_trained_image_feautures = pre_trained_vgg_model(image_input)\n",
        "\n",
        "custom_vgg = tensorflow.keras.models.Model(inputs=image_input, outputs=pre_trained_image_feautures)\n",
        "print (custom_vgg.summary())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "99IlAN3AFVe-"
      },
      "source": [
        "# Define Super Resolution GAN or SR-GAN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-12-24T14:29:35.292557Z",
          "start_time": "2020-12-24T14:29:34.870019Z"
        },
        "id": "nhAQDHWwPq78"
      },
      "outputs": [],
      "source": [
        "low_quality_image = tensorflow.keras.layers.Input(shape=(64, 64, 3))\n",
        "high_quality_input = tensorflow.keras.layers.Input(shape=(256, 256, 3))\n",
        "\n",
        "fake_high_quality_image = generator_network(low_quality_image)\n",
        "\n",
        "discriminator_network.trainable=False\n",
        "custom_vgg.trainable=False\n",
        "\n",
        "d_output = discriminator_network(fake_high_quality_image)\n",
        "fake_high_quality_features = custom_vgg(fake_high_quality_image)\n",
        "\n",
        "sr_gan = tensorflow.keras.models.Model(inputs=[low_quality_image, high_quality_input],\\\n",
        "                                                   outputs=[d_output, fake_high_quality_features])\n",
        "\n",
        "print (sr_gan.summary())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MFyjhkyCFVe_"
      },
      "source": [
        "# Compiling Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-12-24T14:37:37.561370Z",
          "start_time": "2020-12-24T14:37:37.551022Z"
        },
        "id": "rPG_olwXFVe_"
      },
      "outputs": [],
      "source": [
        "sr_gan.compile(loss=['binary_crossentropy', 'mse'], loss_weights=[0.001, 1], optimizer=adam_optimizer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5RpVWMO8FVe_"
      },
      "source": [
        "# Define Data Generators"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VtSLx0fnDakT"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm_notebook\n",
        "new_train = []\n",
        "for file in tqdm_notebook(train):\n",
        "    img = cv2.imread(file)\n",
        "    if (img.shape[0] >= 256):\n",
        "        new_train.append(file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7XEmh1tLD1yZ"
      },
      "outputs": [],
      "source": [
        "len(new_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-12-07T14:13:30.607917Z",
          "start_time": "2020-12-07T14:13:30.590101Z"
        },
        "id": "pTSivi-dFVe_"
      },
      "outputs": [],
      "source": [
        "def get_training_samples(batch_size):\n",
        "    files = np.random.choice(new_train, size=batch_size)\n",
        "    low_quality_images = []\n",
        "    high_quality_images = []\n",
        "    for file in files:\n",
        "        img = cv2.imread(file)\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        img2 = cv2.resize(img, (256, 256))\n",
        "        img3 = cv2.resize(img, (64, 64))\n",
        "        low_quality_images.append((img3-127.5)/127.5)\n",
        "        high_quality_images.append((img2-127.5)/127.5)\n",
        "    low_quality_images = np.array(low_quality_images)\n",
        "    high_quality_images = np.array(high_quality_images)\n",
        "    return low_quality_images, high_quality_images\n",
        "\n",
        "def show_generator_results(generator_network):\n",
        "    low_quality_images, high_quality_images = get_training_samples(3)\n",
        "    fake_high_quality_images = generator_network.predict_on_batch(low_quality_images)\n",
        "\n",
        "    print (\"Low quality input images\")\n",
        "    plt.figure(figsize=(13, 13))\n",
        "    for i in range(3):\n",
        "        plt.subplot(330 + 1 + i)\n",
        "        plt.imshow((low_quality_images[i]+1.0)/2.0)\n",
        "        plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "    print (\"Generated high quality images\")\n",
        "    plt.figure(figsize=(13, 13))\n",
        "    for i in range(3):\n",
        "        plt.subplot(330 + 1 + i)\n",
        "        plt.imshow((fake_high_quality_images[i]+1.0)/2.0)\n",
        "        plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "    print (\"Real high quality images\")\n",
        "    plt.figure(figsize=(13, 13))\n",
        "    for i in range(3):\n",
        "        plt.subplot(330 + 1 + i)\n",
        "        plt.imshow((high_quality_images[i]+1.0)/2.0)\n",
        "        plt.axis('off')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fEOpY_BZFVe_"
      },
      "source": [
        "# Training SR-GAN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-DRb9KgPQBL-"
      },
      "outputs": [],
      "source": [
        "len(new_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-12-07T14:13:32.242860Z",
          "start_time": "2020-12-07T14:13:31.908337Z"
        },
        "id": "E_nihCaQFVe_"
      },
      "outputs": [],
      "source": [
        "epochs = 500\n",
        "batch_size = 1\n",
        "steps = 2000\n",
        "\n",
        "for i in range(0, epochs):\n",
        "    if (i%1 == 0):\n",
        "        show_generator_results(generator_network)\n",
        "    for j in range(steps):\n",
        "        low_quality_images, high_quality_images = get_training_samples(batch_size)\n",
        "\n",
        "        fake_high_quality_images = generator_network.predict_on_batch(low_quality_images)\n",
        "\n",
        "        fake_patch = np.zeros((batch_size, 16, 16, 1))\n",
        "        real_patch = np.ones((batch_size, 16, 16, 1))\n",
        "        \n",
        "        # Updating Discriminator weights\n",
        "        discriminator_network.trainable=True\n",
        "        loss_d_real = discriminator_network.train_on_batch(high_quality_images, real_patch)\n",
        "        loss_d_fake = discriminator_network.train_on_batch(fake_high_quality_images, fake_patch)\n",
        "        loss_d = np.add(loss_d_real, loss_d_fake)/2.0\n",
        "        \n",
        "        # Make the Discriminator belive that these are real samples and calculate loss to train the generator\n",
        "        low_quality_images, high_quality_images = get_training_samples(batch_size)\n",
        "        discriminator_network.trainable=False\n",
        "\n",
        "        real_vgg_features = custom_vgg.predict_on_batch(high_quality_images)\n",
        "\n",
        "        # Updating Generator weights\n",
        "        loss_g = sr_gan.train_on_batch([low_quality_images, high_quality_images], [real_patch, real_vgg_features])\n",
        "        \n",
        "        if j%200 == 0:\n",
        "            print (\"Epoch:%.0f, Step:%.0f, D-Loss:%.3f, D-Acc:%.3f, G-Loss:%.3f\"%(i,j,loss_d[0],loss_d[1]*100,loss_g[0]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tnk-jrvkIBwS"
      },
      "source": [
        "# Check Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xk3cQAD0IfGD"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm_notebook\n",
        "new_test = []\n",
        "for file in tqdm_notebook(test):\n",
        "    img = cv2.imread(file)\n",
        "    if (img.shape[0] >= 256):\n",
        "        new_test.append(file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qeduf2eCIpUE"
      },
      "outputs": [],
      "source": [
        "len(new_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sRVaQNDPIQJI"
      },
      "outputs": [],
      "source": [
        "def show_test_results(generator_network):\n",
        "    files = np.random.choice(new_test, size=3)\n",
        "    low_quality_images = []\n",
        "    high_quality_images = []\n",
        "    for file in files:\n",
        "        img = cv2.imread(file)\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        img2 = cv2.resize(img, (256, 256))\n",
        "        img3 = cv2.resize(img, (64, 64))\n",
        "        low_quality_images.append((img3-127.5)/127.5)\n",
        "        high_quality_images.append((img2-127.5)/127.5)\n",
        "\n",
        "    low_quality_images = np.array(low_quality_images)\n",
        "    high_quality_images = np.array(high_quality_images)\n",
        "\n",
        "    fake_high_quality_images = generator_network.predict_on_batch(low_quality_images)\n",
        "\n",
        "    print (\"Low quality input images\")\n",
        "    plt.figure(figsize=(13, 13))\n",
        "    for i in range(3):\n",
        "        plt.subplot(330 + 1 + i)\n",
        "        plt.imshow((low_quality_images[i]+1.0)/2.0)\n",
        "        plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "    print (\"Generated high quality images\")\n",
        "    plt.figure(figsize=(13, 13))\n",
        "    for i in range(3):\n",
        "        plt.subplot(330 + 1 + i)\n",
        "        plt.imshow((fake_high_quality_images[i]+1.0)/2.0)\n",
        "        plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "    print (\"Real high quality images\")\n",
        "    plt.figure(figsize=(13, 13))\n",
        "    for i in range(3):\n",
        "        plt.subplot(330 + 1 + i)\n",
        "        plt.imshow((high_quality_images[i]+1.0)/2.0)\n",
        "        plt.axis('off')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uk73h_IbQyYA"
      },
      "outputs": [],
      "source": [
        "for i in range(5):\n",
        "    show_test_results(generator_network)\n",
        "    print (\"-\"*100)\n",
        "    print (\"-\"*100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nj-8O_uiN8YE"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Generative Adversarial Network.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}