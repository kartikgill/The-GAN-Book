{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kartikgill/The-GAN-Book/blob/main/Skill-09/Disco-GAN/DiscoGAN-NO-OUTPUTS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4r7FDISrzF3p"
      },
      "source": [
        "# Import Useful Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-12-07T14:13:14.259403Z",
          "start_time": "2020-12-07T14:13:13.565290Z"
        },
        "id": "14h4ejQKFVe9"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm_notebook\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-12-07T14:13:16.982132Z",
          "start_time": "2020-12-07T14:13:14.577444Z"
        },
        "id": "UnlKaodtFVe9"
      },
      "outputs": [],
      "source": [
        "import tensorflow\n",
        "print (tensorflow.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mjoLlfqxzF3v"
      },
      "source": [
        "# Load and Unzip Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JHQwB2seggzy"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive') "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lkpw_LFJf9fb"
      },
      "outputs": [],
      "source": [
        "!unzip /content/gdrive/MyDrive/GAN_datasets/face_scrub.zip -d /"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NQQBPNG2h-Cy"
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "actors = glob.glob('/actor_faces/*/*.jpeg')\n",
        "actress = glob.glob('/actress_faces/*/*.jpeg')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZS3Lq6rHh-Fe"
      },
      "outputs": [],
      "source": [
        "len(actors), len(actress)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tJ0DxtPLh-hQ"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "for file in actors[:10]:\n",
        "    img = cv2.imread(file)\n",
        "    print (img.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AnG8sAs1zF30"
      },
      "source": [
        "# Display few Samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "06Fm26_-h-kE"
      },
      "outputs": [],
      "source": [
        "print (\"Male Actor Faces\")\n",
        "for k in range(2):\n",
        "    plt.figure(figsize=(13, 13))\n",
        "    for j in range(9):\n",
        "        file = np.random.choice(actors)\n",
        "        img = cv2.imread(file)\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        plt.subplot(990 + 1 + j)\n",
        "        plt.imshow(img)\n",
        "        plt.axis('off')\n",
        "        #plt.title(trainY[i])\n",
        "    plt.show()\n",
        "\n",
        "print (\"-\"*80)\n",
        "print (\"Female Actress Faces\")\n",
        "for k in range(2):\n",
        "    plt.figure(figsize=(13, 13))\n",
        "    for j in range(9):\n",
        "        file = np.random.choice(actress)\n",
        "        img = cv2.imread(file)\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        plt.subplot(990 + 1 + j)\n",
        "        plt.imshow(img)\n",
        "        plt.axis('off')\n",
        "        #plt.title(trainY[i])\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kxFTsuaGFVe-"
      },
      "source": [
        "# Define Generator Model (U-Net Like)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EYv50QYoF3wd"
      },
      "outputs": [],
      "source": [
        "import tensorflow_addons as tfa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-12-07T14:13:18.923013Z",
          "start_time": "2020-12-07T14:13:18.914198Z"
        },
        "id": "uZtQ7KmJfoFl"
      },
      "outputs": [],
      "source": [
        "def encoder_layer(input_layer, filters, bn=True):\n",
        "    x = tensorflow.keras.layers.Conv2D(filters, kernel_size=(4,4), strides=(2,2), padding='same')(input_layer)\n",
        "    x = tensorflow.keras.layers.LeakyReLU(alpha=0.2)(x)\n",
        "    if bn:\n",
        "        x = tfa.layers.InstanceNormalization()(x)\n",
        "    return x\n",
        "\n",
        "def decoder_layer(input_layer, skip_input, filters):\n",
        "    x = tensorflow.keras.layers.Conv2DTranspose(filters, kernel_size=(4,4), strides=(2,2), padding='same')(input_layer)\n",
        "    x = tensorflow.keras.layers.Activation('relu')(x)\n",
        "    x = tfa.layers.InstanceNormalization()(x)\n",
        "    x = tensorflow.keras.layers.Concatenate()([x, skip_input])\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-12-07T14:13:19.439926Z",
          "start_time": "2020-12-07T14:13:18.925152Z"
        },
        "id": "3-DrN_4tfoFm"
      },
      "outputs": [],
      "source": [
        "source_image_A = tensorflow.keras.layers.Input(shape=(128, 128, 3))\n",
        "source_image_B = tensorflow.keras.layers.Input(shape=(128, 128, 3))\n",
        "\n",
        "def make_generator():\n",
        "    source_image = tensorflow.keras.layers.Input(shape=(128, 128, 3))\n",
        "\n",
        "    e1 = encoder_layer(source_image, 64, bn=False)\n",
        "    e2 = encoder_layer(e1, 128)\n",
        "    e3 = encoder_layer(e2, 256)\n",
        "    # e4 = encoder_layer(e3, 256)\n",
        "    e5 = encoder_layer(e3, 512)\n",
        "    e6 = encoder_layer(e5, 512)\n",
        "    e7 = encoder_layer(e6, 512)\n",
        "\n",
        "    bottle_neck = tensorflow.keras.layers.Conv2D(512, (4,4), strides=(2,2), padding='same')(e7)\n",
        "    b = tensorflow.keras.layers.Activation('relu')(bottle_neck)\n",
        "\n",
        "    d1 = decoder_layer(b, e7, 512)\n",
        "    d2 = decoder_layer(d1, e6, 512)\n",
        "    d3 = decoder_layer(d2, e5, 512)\n",
        "    # d4 = decoder_layer(d3, e4, 256)\n",
        "    d5 = decoder_layer(d3, e3, 256)\n",
        "    d6 = decoder_layer(d5, e2, 128)\n",
        "    d7 = decoder_layer(d6, e1, 64)\n",
        "\n",
        "    decoded = tensorflow.keras.layers.Conv2DTranspose(3, kernel_size=(4,4), strides=(2,2), padding='same')(d7)\n",
        "    translated_image = tensorflow.keras.layers.Activation('tanh')(decoded)\n",
        "    return source_image, translated_image\n",
        "\n",
        "source_image, translated_image = make_generator()\n",
        "generator_network_AB = tensorflow.keras.models.Model(inputs=source_image, outputs=translated_image)\n",
        "\n",
        "source_image, translated_image = make_generator()\n",
        "generator_network_BA = tensorflow.keras.models.Model(inputs=source_image, outputs=translated_image)\n",
        "\n",
        "print (generator_network_AB.summary())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eQOF8YEKfoFm"
      },
      "source": [
        "# Define Discriminator Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-12-07T14:13:23.056463Z",
          "start_time": "2020-12-07T14:13:23.051889Z"
        },
        "id": "gXTFSDKafoFm"
      },
      "outputs": [],
      "source": [
        "def my_conv_layer(input_layer, filters, bn=True):\n",
        "    x = tensorflow.keras.layers.Conv2D(filters, kernel_size=(4,4), strides=(2,2), padding='same')(input_layer)\n",
        "    x = tensorflow.keras.layers.LeakyReLU(alpha=0.2)(x)\n",
        "    if bn:\n",
        "        #x = tensorflow.keras.layers.BatchNormalization(momentum=0.8)(x)\n",
        "        x = tfa.layers.InstanceNormalization()(x)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-12-07T14:13:23.614999Z",
          "start_time": "2020-12-07T14:13:23.494963Z"
        },
        "id": "1GCaEdctfoFn"
      },
      "outputs": [],
      "source": [
        " def make_discriminator():\n",
        "    target_image_input = tensorflow.keras.layers.Input(shape=(128, 128, 3))\n",
        "\n",
        "    x = my_conv_layer(target_image_input, 64, bn=False)\n",
        "    x = my_conv_layer(x, 128)\n",
        "    x = my_conv_layer(x, 256)\n",
        "    # x = my_conv_layer(x, 512)\n",
        "    x = my_conv_layer(x, 512)\n",
        "\n",
        "    patch_features = tensorflow.keras.layers.Conv2D(1, kernel_size=(4,4), strides=(1,1), padding='same')(x)\n",
        "    return target_image_input, patch_features\n",
        "\n",
        "\n",
        "target_image_input, patch_features = make_discriminator()\n",
        "discriminator_network_A = tensorflow.keras.models.Model(inputs=target_image_input, outputs=patch_features)\n",
        "\n",
        "target_image_input, patch_features = make_discriminator()\n",
        "discriminator_network_B = tensorflow.keras.models.Model(inputs=target_image_input, outputs=patch_features)\n",
        "\n",
        "print (discriminator_network_A.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-12-07T14:13:25.031780Z",
          "start_time": "2020-12-07T14:13:25.007978Z"
        },
        "id": "tMc1CyNNFVe-"
      },
      "outputs": [],
      "source": [
        "adam_optimizer = tensorflow.keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5)\n",
        "discriminator_network_A.compile(loss='mse', optimizer=adam_optimizer, metrics=['accuracy'])\n",
        "discriminator_network_B.compile(loss='mse', optimizer=adam_optimizer, metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "99IlAN3AFVe-"
      },
      "source": [
        "# Define DISCO-GAN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-12-07T14:13:27.560907Z",
          "start_time": "2020-12-07T14:13:26.356565Z"
        },
        "id": "mjnxFr21FVe-"
      },
      "outputs": [],
      "source": [
        "# Domain Transfer\n",
        "fake_B = generator_network_AB(source_image_A)\n",
        "fake_A = generator_network_BA(source_image_B)\n",
        "\n",
        "# Restoring original Domain\n",
        "get_back_A = generator_network_BA(fake_B)\n",
        "get_back_B = generator_network_AB(fake_A)\n",
        "  \n",
        "discriminator_network_A.trainable=False\n",
        "discriminator_network_B.trainable=False\n",
        "\n",
        "# Tell Real vs Fake, for a given domain\n",
        "verify_A = discriminator_network_A(fake_A)\n",
        "verify_B = discriminator_network_B(fake_B)\n",
        "\n",
        "disco_gan = tensorflow.keras.models.Model(inputs = [source_image_A, source_image_B], \\\n",
        "                              outputs = [verify_A, verify_B, fake_B, fake_A, get_back_A, get_back_B])\n",
        "disco_gan.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MFyjhkyCFVe_"
      },
      "source": [
        "# Compiling Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-12-07T14:13:29.237433Z",
          "start_time": "2020-12-07T14:13:29.221523Z"
        },
        "id": "rPG_olwXFVe_"
      },
      "outputs": [],
      "source": [
        "disco_gan.compile(loss=['mse', 'mse', 'mae', 'mae', 'mae', 'mae'], optimizer=adam_optimizer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5RpVWMO8FVe_"
      },
      "source": [
        "# Define Data Generators"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-12-07T14:13:30.607917Z",
          "start_time": "2020-12-07T14:13:30.590101Z"
        },
        "id": "pTSivi-dFVe_"
      },
      "outputs": [],
      "source": [
        "def actors_to_actress(actors, generator_network):\n",
        "    generated_samples = generator_network.predict_on_batch(actors)\n",
        "    return generated_samples\n",
        "\n",
        "def actress_to_actors(actress, generator_network):\n",
        "    generated_samples = generator_network.predict_on_batch(actress)\n",
        "    return generated_samples\n",
        "\n",
        "def get_actor_samples(batch_size):\n",
        "    random_files = np.random.choice(actors, size=batch_size)\n",
        "    images = []\n",
        "    for file in random_files:\n",
        "        img = cv2.imread(file)\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        img = cv2.resize(img, (128, 128))\n",
        "        images.append((img-127.5)/127.5)\n",
        "    actor_images = np.array(images)\n",
        "    return actor_images\n",
        "\n",
        "def get_actress_samples(batch_size):\n",
        "    random_files = np.random.choice(actress, size=batch_size)\n",
        "    images = []\n",
        "    for file in random_files:\n",
        "        img = cv2.imread(file)\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        img = cv2.resize(img, (128, 128))\n",
        "        images.append((img-127.5)/127.5)\n",
        "    actress_images = np.array(images)\n",
        "    return actress_images\n",
        "\n",
        "def show_generator_results_actor_to_actress(generator_network_AB, generator_network_BA):\n",
        "    images = []\n",
        "    for j in range(7):\n",
        "        file = np.random.choice(actors)\n",
        "        img = cv2.imread(file)\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        img = cv2.resize(img, (128, 128))\n",
        "        images.append(img)\n",
        "\n",
        "    print ('Input Actor Images')\n",
        "    plt.figure(figsize=(13, 13))\n",
        "    for j, img in enumerate(images):\n",
        "        plt.subplot(770 + 1 + j)\n",
        "        plt.imshow(img)\n",
        "        plt.axis('off')\n",
        "        #plt.title(trainY[i])\n",
        "    plt.show()\n",
        "\n",
        "    print ('Translated (Actor -> Actress) Images')\n",
        "    translated = []\n",
        "    plt.figure(figsize=(13, 13))\n",
        "    for j, img in enumerate(images):\n",
        "        img = (img-127.5)/127.5\n",
        "        output = actors_to_actress(np.array([img]), generator_network_AB)[0]\n",
        "        translated.append(output)\n",
        "        output = (output+1.0)/2.0\n",
        "        plt.subplot(770 + 1 + j)\n",
        "        plt.imshow(output)\n",
        "        plt.axis('off')\n",
        "        #plt.title(trainY[i])\n",
        "    plt.show()\n",
        "\n",
        "    print ('Translated reverse ( Fake Actress -> Fake Actor)')\n",
        "    plt.figure(figsize=(13, 13))\n",
        "    for j, img in enumerate(translated):\n",
        "        output = actress_to_actors(np.array([img]), generator_network_BA)[0]\n",
        "        output = (output+1.0)/2.0\n",
        "        plt.subplot(770 + 1 + j)\n",
        "        plt.imshow(output)\n",
        "        plt.axis('off')\n",
        "        #plt.title(trainY[i])\n",
        "    plt.show()\n",
        "\n",
        "def show_generator_results_actress_to_actor(generator_network_AB, generator_network_BA):\n",
        "    images = []\n",
        "    for j in range(7):\n",
        "        file = np.random.choice(actress)\n",
        "        img = cv2.imread(file)\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        img = cv2.resize(img, (128, 128))\n",
        "        images.append(img)\n",
        "\n",
        "    print ('Input Actress Images')\n",
        "    plt.figure(figsize=(13, 13))\n",
        "    for j, img in enumerate(images):\n",
        "        plt.subplot(770 + 1 + j)\n",
        "        plt.imshow(img)\n",
        "        plt.axis('off')\n",
        "        #plt.title(trainY[i])\n",
        "    plt.show()\n",
        "\n",
        "    print ('Translated (Actress -> Actor) Images')\n",
        "    translated = []\n",
        "    plt.figure(figsize=(13, 13))\n",
        "    for j, img in enumerate(images):\n",
        "        img = (img-127.5)/127.5\n",
        "        output = actress_to_actors(np.array([img]), generator_network_BA)[0]\n",
        "        translated.append(output)\n",
        "        output = (output+1.0)/2.0\n",
        "        plt.subplot(770 + 1 + j)\n",
        "        plt.imshow(output)\n",
        "        plt.axis('off')\n",
        "        #plt.title(trainY[i])\n",
        "    plt.show()\n",
        "\n",
        "    print ('Translated reverse (Fake Actor -> Fake Actress)')\n",
        "    plt.figure(figsize=(13, 13))\n",
        "    for j, img in enumerate(translated):\n",
        "        output = actors_to_actress(np.array([img]), generator_network_AB)[0]\n",
        "        output = (output+1.0)/2.0\n",
        "        plt.subplot(770 + 1 + j)\n",
        "        plt.imshow(output)\n",
        "        plt.axis('off')\n",
        "        #plt.title(trainY[i])\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fEOpY_BZFVe_"
      },
      "source": [
        "# Training Disco-GAN Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lg6OKd4qmIdh"
      },
      "outputs": [],
      "source": [
        "len(actors), len(actress)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-12-07T14:13:32.242860Z",
          "start_time": "2020-12-07T14:13:31.908337Z"
        },
        "id": "E_nihCaQFVe_"
      },
      "outputs": [],
      "source": [
        "epochs = 500\n",
        "batch_size = 1\n",
        "steps = 2000\n",
        "\n",
        "for i in range(0, epochs):\n",
        "    if i%1 == 0:\n",
        "        show_generator_results_actor_to_actress(generator_network_AB, generator_network_BA)\n",
        "        print (\"-\"*100)\n",
        "        show_generator_results_actress_to_actor(generator_network_AB, generator_network_BA)\n",
        "    for j in range(steps):  \n",
        "        # A == Actor\n",
        "        # B == Actress\n",
        "        domain_A_images = get_actor_samples(batch_size)\n",
        "        domain_B_images = get_actress_samples(batch_size)\n",
        "\n",
        "        fake_patch = np.zeros((batch_size, 8, 8, 1))\n",
        "        real_patch = np.ones((batch_size, 8, 8, 1))\n",
        "        \n",
        "        fake_B_images = generator_network_AB(domain_A_images)\n",
        "        fake_A_images = generator_network_BA(domain_B_images)\n",
        "        \n",
        "        # Updating Discriminator A weights\n",
        "        discriminator_network_A.trainable=True\n",
        "        discriminator_network_B.trainable=False\n",
        "        loss_d_real_A = discriminator_network_A.train_on_batch(domain_A_images, real_patch)\n",
        "        loss_d_fake_A = discriminator_network_A.train_on_batch(fake_A_images, fake_patch)\n",
        "        \n",
        "        loss_d_A = np.add(loss_d_real_A, loss_d_fake_A)/2.0\n",
        "        \n",
        "        # Updating Discriminator B weights\n",
        "        discriminator_network_B.trainable=True\n",
        "        discriminator_network_A.trainable=False\n",
        "        loss_d_real_B = discriminator_network_B.train_on_batch(domain_B_images, real_patch)\n",
        "        loss_d_fake_B = discriminator_network_B.train_on_batch(fake_B_images, fake_patch)\n",
        "        \n",
        "        loss_d_B = np.add(loss_d_real_B, loss_d_fake_B)/2.0\n",
        "        \n",
        "        # Make the Discriminator belive that these are real samples and calculate loss to train the generator\n",
        "        \n",
        "        discriminator_network_A.trainable=False\n",
        "        discriminator_network_B.trainable=False\n",
        "\n",
        "        # Updating Generator weights\n",
        "        loss_g = disco_gan.train_on_batch([domain_A_images, domain_B_images],\\\n",
        "                    [real_patch, real_patch, domain_B_images, domain_A_images, domain_A_images, domain_B_images])\n",
        "        \n",
        "        if j%200 == 0:\n",
        "            print (\"Epoch:%.0f, Step:%.0f, DA-Loss:%.3f, DA-Acc:%.3f, DB-Loss:%.3f, DB-Acc:%.3f, G-Loss:%.3f\"\\\n",
        "                   %(i,j,loss_d_A[0],loss_d_A[1]*100,loss_d_B[0],loss_d_B[1]*100,loss_g[0]))\n",
        "            "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hIKM9tkYGl26"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Generative Adversarial Network.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}